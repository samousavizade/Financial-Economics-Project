{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.covariance import MinCovDet, EmpiricalCovariance, ShrunkCovariance, LedoitWolf, OAS\n",
    "from scipy.optimize import minimize\n",
    "from scipy.cluster.hierarchy import average, complete, single, dendrogram\n",
    "from matplotlib import pyplot as plt\n",
    "# from mlfinlab.portfolio_optimization.estimators.returns_estimators import ReturnsEstimators\n",
    "\n",
    "\n",
    "class RiskEstimators:\n",
    "    \"\"\"\n",
    "    This class contains the implementations for different ways to calculate and adjust Covariance matrices.\n",
    "    The functions related to de-noising and de-toning the Covariance matrix are reproduced with modification\n",
    "    from Chapter 2 of the the following book:\n",
    "    Marcos Lopez de Prado “Machine Learning for Asset Managers”, (2020).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def minimum_covariance_determinant(returns, price_data=False, assume_centered=False,\n",
    "                                       support_fraction=None, random_state=None):\n",
    "        \"\"\"\n",
    "        Calculates the Minimum Covariance Determinant for a dataframe of asset prices or returns.\n",
    "        This function is a wrap of the sklearn's MinCovDet (MCD) class. According to the\n",
    "        scikit-learn User Guide on Covariance estimation:\n",
    "        \"The idea is to find a given proportion (h) of “good” observations that are not outliers\n",
    "        and compute their empirical covariance matrix. This empirical covariance matrix is then\n",
    "        rescaled to compensate for the performed selection of observations\".\n",
    "        Link to the documentation:\n",
    "        <https://scikit-learn.org/stable/modules/generated/sklearn.covariance.MinCovDet.html>`_\n",
    "        If a dataframe of prices is given, it is transformed into a dataframe of returns using\n",
    "        the calculate_returns method from the ReturnsEstimators class.\n",
    "        :param returns: (pd.DataFrame) Dataframe where each column is a series of returns or prices for an asset.\n",
    "        :param price_data: (bool) Flag if prices of assets are used and not returns. (False by default)\n",
    "        :param assume_centered: (bool) Flag for data with mean significantly equal to zero.\n",
    "                                       (Read the documentation for MinCovDet class, False by default)\n",
    "        :param support_fraction: (float) Values between 0 and 1. The proportion of points to be included in the support\n",
    "                                         of the raw MCD estimate. (Read the documentation for MinCovDet class,\n",
    "                                         None by default)\n",
    "        :param random_state: (int) Seed used by the random number generator. (None by default)\n",
    "        :return: (np.array) Estimated robust covariance matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def empirical_covariance(returns, price_data=False, assume_centered=False):\n",
    "        \"\"\"\n",
    "        Calculates the Maximum likelihood covariance estimator for a dataframe of asset prices or returns.\n",
    "        This function is a wrap of the sklearn's EmpiricalCovariance class. According to the\n",
    "        scikit-learn User Guide on Covariance estimation:\n",
    "        \"The covariance matrix of a data set is known to be well approximated by the classical maximum\n",
    "        likelihood estimator, provided the number of observations is large enough compared to the number\n",
    "        of features (the variables describing the observations). More precisely, the Maximum Likelihood\n",
    "        Estimator of a sample is an unbiased estimator of the corresponding population’s covariance matrix\".\n",
    "        Link to the documentation:\n",
    "        <https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EmpiricalCovariance.html>`_\n",
    "        If a dataframe of prices is given, it is transformed into a dataframe of returns using\n",
    "        the calculate_returns method from the ReturnsEstimators class.\n",
    "        :param returns: (pd.DataFrame) Dataframe where each column is a series of returns or prices for an asset.\n",
    "        :param price_data: (bool) Flag if prices of assets are used and not returns. (False by default)\n",
    "        :param assume_centered: (bool) Flag for data with mean almost, but not exactly zero.\n",
    "                                       (Read documentation for EmpiricalCovariance class, False by default)\n",
    "        :return: (np.array) Estimated covariance matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def shrinked_covariance(returns, price_data=False, shrinkage_type='basic', assume_centered=False,\n",
    "                            basic_shrinkage=0.1):\n",
    "        \"\"\"\n",
    "        Calculates the Covariance estimator with shrinkage for a dataframe of asset prices or returns.\n",
    "        This function allows three types of shrinkage - Basic, Ledoit-Wolf and Oracle Approximating Shrinkage.\n",
    "        It is a wrap of the sklearn's ShrunkCovariance, LedoitWolf and OAS classes. According to the\n",
    "        scikit-learn User Guide on Covariance estimation:\n",
    "        \"Sometimes, it even occurs that the empirical covariance matrix cannot be inverted for numerical\n",
    "        reasons. To avoid such an inversion problem, a transformation of the empirical covariance matrix\n",
    "        has been introduced: the shrinkage. Mathematically, this shrinkage consists in reducing the ratio\n",
    "        between the smallest and the largest eigenvalues of the empirical covariance matrix\".\n",
    "        Link to the documentation:\n",
    "        <https://scikit-learn.org/stable/modules/covariance.html>`_\n",
    "        If a dataframe of prices is given, it is transformed into a dataframe of returns using\n",
    "        the calculate_returns method from the ReturnsEstimators class.\n",
    "        :param returns: (pd.DataFrame) Dataframe where each column is a series of returns or prices for an asset.\n",
    "        :param price_data: (bool) Flag if prices of assets are used and not returns. (False by default)\n",
    "        :param shrinkage_type: (str) Type of shrinkage to use. (``basic`` by default, ``lw``, ``oas``, ``all``)\n",
    "        :param assume_centered: (bool) Flag for data with mean almost, but not exactly zero.\n",
    "                                       (Read documentation for chosen shrinkage class, False by default)\n",
    "        :param basic_shrinkage: (float) Between 0 and 1. Coefficient in the convex combination for basic shrinkage.\n",
    "                                        (0.1 by default)\n",
    "        :return: (np.array) Estimated covariance matrix. Tuple of covariance matrices if shrinkage_type = ``all``.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def semi_covariance(returns, price_data=False, threshold_return=0):\n",
    "        \"\"\"\n",
    "        Calculates the Semi-Covariance matrix for a dataframe of asset prices or returns.\n",
    "        Semi-Covariance matrix is used to calculate the portfolio's downside volatility. Usually, the\n",
    "        threshold return is zero and the negative volatility is measured. A threshold can be a positive number\n",
    "        when one assumes a required return rate. If the threshold is above zero, the output is the volatility\n",
    "        measure for returns below this threshold.\n",
    "        If a dataframe of prices is given, it is transformed into a dataframe of returns using\n",
    "        the calculate_returns method from the ReturnsEstimators class.\n",
    "        :param returns: (pd.DataFrame) Dataframe where each column is a series of returns or prices for an asset.\n",
    "        :param price_data: (bool) Flag if prices of assets are used and not returns. (False by default)\n",
    "        :param threshold_return: (float) Required return for each period in the frequency of the input data.\n",
    "                                         (If the input data is daily, it's a daily threshold return, 0 by default)\n",
    "        :return: (np.array) Semi-Covariance matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def exponential_covariance(returns, price_data=False, window_span=60):\n",
    "        \"\"\"\n",
    "        Calculates the Exponentially-weighted Covariance matrix for a dataframe of asset prices or returns.\n",
    "        It calculates the series of covariances between elements and then gets the last value of exponentially\n",
    "        weighted moving average series from covariance series as an element in matrix.\n",
    "        If a dataframe of prices is given, it is transformed into a dataframe of returns using\n",
    "        the calculate_returns method from the ReturnsEstimators class.\n",
    "        :param returns: (pd.DataFrame) Dataframe where each column is a series of returns or prices for an asset.\n",
    "        :param price_data: (bool) Flag if prices of assets are used and not returns. (False by default)\n",
    "        :param window_span: (int) Used to specify decay in terms of span for the exponentially-weighted series.\n",
    "                                  (60 by default)\n",
    "        :return: (np.array) Exponentially-weighted Covariance matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_corr_hierarchical(cor_matrix, method='complete', draw_plot=False):\n",
    "        \"\"\"\n",
    "        Creates a filtered correlation matrix using hierarchical clustering methods from an empirical\n",
    "        correlation matrix, given that all values are non-negative [0 ~ 1]\n",
    "        This function allows for three types of hierarchical clustering - complete, single, and average\n",
    "        linkage clusters. Link to hierarchical clustering methods documentation:\n",
    "        `<https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html>`_\n",
    "        It works as follows:\n",
    "        First, the method creates a hierarchical clustering tree using scipy's hierarchical clustering methods\n",
    "        from the empirical 2-D correlation matrix.\n",
    "        Second, it extracts and stores each cluster's filtered value (alpha) and assigns it to it's corresponding leaf.\n",
    "        Finally, we create a new filtered matrix by assigning each of the correlations to their corresponding\n",
    "        parent node's alpha value.\n",
    "        \n",
    "        :param cor_matrix: (np.array) Numpy array of an empirical correlation matrix.\n",
    "        :param method: (str) Hierarchical clustering method to use. (``complete`` by default, ``single``, ``average``)\n",
    "        :param draw_plot: (bool) Plots the hierarchical cluster tree. (False by default)\n",
    "        :return: (np.array) The filtered correlation matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def denoise_covariance(self, cov, tn_relation, denoise_method='const_resid_eigen', detone=False,\n",
    "                           market_component=1, kde_bwidth=0.01, alpha=0):\n",
    "        \"\"\"\n",
    "        De-noises the covariance matrix or the correlation matrix.\n",
    "        Two denoising methods are supported:\n",
    "        1. Constant Residual Eigenvalue Method (``const_resid_eigen``)\n",
    "        2. Spectral Method (``spectral``)\n",
    "        3. Targeted Shrinkage Method (``target_shrink``)\n",
    "        The Constant Residual Eigenvalue Method works as follows:\n",
    "        First, a correlation is calculated from the covariance matrix (if the input is the covariance matrix).\n",
    "        Second, eigenvalues and eigenvectors of the correlation matrix are calculated using the linalg.eigh\n",
    "        function from numpy package.\n",
    "        Third, a maximum theoretical eigenvalue is found by fitting Marcenko-Pastur (M-P) distribution\n",
    "        to the empirical distribution of the correlation matrix eigenvalues. The empirical distribution\n",
    "        is obtained through kernel density estimation using the KernelDensity class from sklearn.\n",
    "        The fit of the M-P distribution is done by minimizing the Sum of Squared estimate of Errors\n",
    "        between the theoretical pdf and the kernel. The minimization is done by adjusting the variation\n",
    "        of the M-P distribution.\n",
    "        Fourth, the eigenvalues of the correlation matrix are sorted and the eigenvalues lower than\n",
    "        the maximum theoretical eigenvalue are set to their average value. This is how the eigenvalues\n",
    "        associated with noise are shrinked. The de-noised covariance matrix is then calculated back\n",
    "        from new eigenvalues and eigenvectors.\n",
    "        The Spectral Method works just like the Constant Residual Eigenvalue Method, but instead of replacing\n",
    "        eigenvalues lower than the maximum theoretical eigenvalue to their average value, they are replaced with\n",
    "        zero instead.\n",
    "        The Targeted Shrinkage Method works as follows:\n",
    "        First, a correlation is calculated from the covariance matrix (if the input is the covariance matrix).\n",
    "        Second, eigenvalues and eigenvectors of the correlation matrix are calculated using the linalg.eigh\n",
    "        function from numpy package.\n",
    "        Third, the correlation matrix composed from eigenvectors and eigenvalues related to noise is\n",
    "        shrunk using the alpha variable. The shrinkage is done by summing the noise correlation matrix\n",
    "        multiplied by alpha to the diagonal of the noise correlation matrix multiplied by (1-alpha).\n",
    "        Fourth, the shrinked noise correlation matrix is summed to the information correlation matrix.\n",
    "        Correlation matrix can also be detoned by excluding a number of first eigenvectors representing\n",
    "        the market component.\n",
    "        These algorithms are reproduced with minor modifications from the following book:\n",
    "        Marcos Lopez de Prado “Machine Learning for Asset Managers”, (2020).\n",
    "        :param cov: (np.array) Covariance matrix or correlation matrix.\n",
    "        :param tn_relation: (float) Relation of sample length T to the number of variables N used to calculate the\n",
    "                                    covariance matrix.\n",
    "        :param denoise_method: (str) Denoising methos to use. (``const_resid_eigen`` by default, ``target_shrink``)\n",
    "        :param detone: (bool) Flag to detone the matrix. (False by default)\n",
    "        :param market_component: (int) Number of fist eigevectors related to a market component. (1 by default)\n",
    "        :param kde_bwidth: (float) The bandwidth of the kernel to fit KDE.\n",
    "        :param alpha: (float) In range (0 to 1) - shrinkage of the noise correlation matrix to use in the\n",
    "                              Targeted Shrinkage Method. (0 by default)\n",
    "        :return: (np.array) De-noised covariance matrix or correlation matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def corr_to_cov(corr, std):\n",
    "        \"\"\"\n",
    "        Recovers the covariance matrix from a correlation matrix.\n",
    "        Requires a vector of standard deviations of variables - square root\n",
    "        of elements on the main diagonal fo the covariance matrix.\n",
    "        Formula used: Cov = Corr * OuterProduct(std, std)\n",
    "        :param corr: (np.array) Correlation matrix.\n",
    "        :param std: (np.array) Vector of standard deviations.\n",
    "        :return: (np.array) Covariance matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def cov_to_corr(cov):\n",
    "        \"\"\"\n",
    "        Derives the correlation matrix from a covariance matrix.\n",
    "        Formula used: Corr = Cov / OuterProduct(std, std)\n",
    "        :param cov: (np.array) Covariance matrix.\n",
    "        :return: (np.array) Covariance matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def is_matrix_invertible(matrix):\n",
    "        \"\"\"\n",
    "        Check if a matrix is invertible or not.\n",
    "        :param matrix: (Numpy matrix) A matrix whose invertibility we want to check.\n",
    "        :return: (bool) Boolean value depending on whether the matrix is invertible or not.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _fit_kde(observations, kde_bwidth=0.01, kde_kernel='gaussian', eval_points=None):\n",
    "        \"\"\"\n",
    "        Fits kernel to a series of observations (in out case eigenvalues), and derives the\n",
    "        probability density function of observations.\n",
    "        The function used to fit kernel is KernelDensity from sklearn.neighbors. Fit of the KDE\n",
    "        can be evaluated on a given set of points, passed as eval_points variable.\n",
    "        :param observations: (np.array) Array of observations (eigenvalues) eigenvalues to fit kernel to.\n",
    "        :param kde_bwidth: (float) The bandwidth of the kernel. (0.01 by default)\n",
    "        :param kde_kernel: (str) Kernel to use [``gaussian`` by default, ``tophat``, ``epanechnikov``, ``exponential``,\n",
    "                                 ``linear``,``cosine``].\n",
    "        :param eval_points: (np.array) Array of values on which the fit of the KDE will be evaluated.\n",
    "                                       If None, the unique values of observations are used. (None by default)\n",
    "        :return: (pd.Series) Series with estimated pdf values in the eval_points.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _mp_pdf(var, tn_relation, num_points):\n",
    "        \"\"\"\n",
    "        Derives the pdf of the Marcenko-Pastur distribution.\n",
    "        Outputs the pdf for num_points between the minimum and maximum expected eigenvalues.\n",
    "        Requires the variance of the distribution (var) and the relation of T - the number\n",
    "        of observations of each X variable to N - the number of X variables (T/N).\n",
    "        :param var: (float) Variance of the M-P distribution.\n",
    "        :param tn_relation: (float) Relation of sample length T to the number of variables N (T/N).\n",
    "        :param num_points: (int) Number of points to estimate pdf.\n",
    "        :return: (pd.Series) Series of M-P pdf values.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _pdf_fit(self, var, eigen_observations, tn_relation, kde_bwidth, num_points=1000):\n",
    "        \"\"\"\n",
    "        Calculates the fit (Sum of Squared estimate of Errors) of the empirical pdf\n",
    "        (kernel density estimation) to the theoretical pdf (Marcenko-Pastur distribution).\n",
    "        SSE is calculated for num_points, equally spread between minimum and maximum\n",
    "        expected theoretical eigenvalues.\n",
    "        :param var: (float) Variance of the M-P distribution. (for the theoretical pdf)\n",
    "        :param eigen_observations: (np.array) Observed empirical eigenvalues. (for the empirical pdf)\n",
    "        :param tn_relation: (float) Relation of sample length T to the number of variables N. (for the theoretical pdf)\n",
    "        :param kde_bwidth: (float) The bandwidth of the kernel. (for the empirical pdf)\n",
    "        :param num_points: (int) Number of points to estimate pdf. (for the empirical pdf, 1000 by default)\n",
    "        :return: (float) SSE between empirical pdf and theoretical pdf.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _find_max_eval(self, eigen_observations, tn_relation, kde_bwidth):\n",
    "        \"\"\"\n",
    "        Searching for maximum random eigenvalue by fitting Marcenko-Pastur distribution\n",
    "        to the empirical one - obtained through kernel density estimation. The fit is done by\n",
    "        minimizing the Sum of Squared estimate of Errors between the theoretical pdf and the\n",
    "        kernel fit. The minimization is done by adjusting the variation of the M-P distribution.\n",
    "        :param eigen_observations: (np.array) Observed empirical eigenvalues. (for the empirical pdf)\n",
    "        :param tn_relation: (float) Relation of sample length T to the number of variables N. (for the theoretical pdf)\n",
    "        :param kde_bwidth: (float) The bandwidth of the kernel. (for the empirical pdf)\n",
    "        :return: (float, float) Maximum random eigenvalue, optimal variation of the Marcenko-Pastur distribution.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_pca(hermit_matrix):\n",
    "        \"\"\"\n",
    "        Calculates eigenvalues and eigenvectors from a Hermitian matrix. In our case, from the correlation matrix.\n",
    "        Function used to calculate the eigenvalues and eigenvectors is linalg.eigh from numpy package.\n",
    "        Eigenvalues in the output are placed on the main diagonal of a matrix.\n",
    "        :param hermit_matrix: (np.array) Hermitian matrix.\n",
    "        :return: (np.array, np.array) Eigenvalues matrix, eigenvectors array.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _denoised_corr(self, eigenvalues, eigenvectors, num_facts):\n",
    "        \"\"\"\n",
    "        De-noises the correlation matrix using the Constant Residual Eigenvalue method.\n",
    "        The input is the eigenvalues and the eigenvectors of the correlation matrix and the number\n",
    "        of the first eigenvalue that is below the maximum theoretical eigenvalue.\n",
    "        De-noising is done by shrinking the eigenvalues associated with noise (the eigenvalues lower than\n",
    "        the maximum theoretical eigenvalue are set to a constant eigenvalue, preserving the trace of the\n",
    "        correlation matrix).\n",
    "        The result is the de-noised correlation matrix.\n",
    "        :param eigenvalues: (np.array) Matrix with eigenvalues on the main diagonal.\n",
    "        :param eigenvectors: (float) Eigenvectors array.\n",
    "        :param num_facts: (float) Threshold for eigenvalues to be fixed.\n",
    "        :return: (np.array) De-noised correlation matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _denoised_corr_targ_shrink(eigenvalues, eigenvectors, num_facts, alpha=0):\n",
    "        \"\"\"\n",
    "        De-noises the correlation matrix using the Targeted Shrinkage method.\n",
    "        The input is the correlation matrix, the eigenvalues and the eigenvectors of the correlation\n",
    "        matrix and the number of the first eigenvalue that is below the maximum theoretical eigenvalue\n",
    "        and the shrinkage coefficient for the eigenvectors and eigenvalues associated with noise.\n",
    "        Shrinks strictly the random eigenvalues - eigenvalues below the maximum theoretical eigenvalue.\n",
    "        The result is the de-noised correlation matrix.\n",
    "        :param eigenvalues: (np.array) Matrix with eigenvalues on the main diagonal.\n",
    "        :param eigenvectors: (float) Eigenvectors array.\n",
    "        :param num_facts: (float) Threshold for eigenvalues to be fixed.\n",
    "        :param alpha: (float) In range (0 to 1) - shrinkage among the eigenvectors.\n",
    "                              and eigenvalues associated with noise. (0 by default)\n",
    "        :return: (np.array) De-noised correlation matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _detoned_corr(self, corr, market_component=1):\n",
    "        \"\"\"\n",
    "        De-tones the correlation matrix by removing the market component.\n",
    "        The input is the eigenvalues and the eigenvectors of the correlation matrix and the number\n",
    "        of the first eigenvalue that is above the maximum theoretical eigenvalue and the number of\n",
    "        eigenvectors related to a market component.\n",
    "        :param corr: (np.array) Correlation matrix to detone.\n",
    "        :param market_component: (int) Number of fist eigevectors related to a market component. (1 by default)\n",
    "        :return: (np.array) De-toned correlation matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _denoised_corr_spectral(self, eigenvalues, eigenvectors, num_facts):\n",
    "        \"\"\"\n",
    "        De-noises the correlation matrix using the Spectral method.\n",
    "        The input is the eigenvalues and the eigenvectors of the correlation matrix and the number\n",
    "        of the first eigenvalue that is below the maximum theoretical eigenvalue.\n",
    "        De-noising is done by shrinking the eigenvalues associated with noise (the eigenvalues lower than\n",
    "        the maximum theoretical eigenvalue are set to zero, preserving the trace of the\n",
    "        correlation matrix).\n",
    "        The result is the de-noised correlation matrix.\n",
    "        :param eigenvalues: (np.array) Matrix with eigenvalues on the main diagonal.\n",
    "        :param eigenvectors: (float) Eigenvectors array.\n",
    "        :param num_facts: (float) Threshold for eigenvalues to be fixed.\n",
    "        :return: (np.array) De-noised correlation matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
